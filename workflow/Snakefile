import os
import json
import yaml
import shutil

from pathlib import Path
from snakemake.utils import validate


include: "rules/common.smk"


configfile: os.path.join(workflow.basedir, "../config/config.yaml")


envvars:
    "TMPDIR",


validate(
    config,
    str(workflow.main_snakefile).replace(
        "workflow/Snakefile", "config/config.schema.yaml"
    ),
)

SHARDS = make_shard_names(config["nshards"])


onstart:
    with open("config_used.yml", "w") as outfile:
        yaml.dump(config, outfile)

    if not os.path.exists("logs"):
        os.makedirs("logs")


localrules:
    all,


if config["stage"] == "all":
    config["assembly"] = f"{config['sample']}.assembly.fasta"

# we have to fix some inputs to downstream applications if we are running all together:
# we do this for the assembly because that config entry is referenced many times in the binning and annotation workflows
# for entries like R1/R2, its eaiest to set those in the conditional block below, as those are only used by a single rule within a given workflow


#
# Preprocess Module
#
module preprocess:
    snakefile:
        "rules/preprocess.smk"
    config:
        config
    skip_validation:
        True


use rule * from preprocess as preprocess_*


#
# Biobakery Module
#
module biobakery:
    snakefile:
        "rules/biobakery.smk"
    config:
        config
    skip_validation:
        True


use rule * from biobakery as biobakery_*


#
# Kraken Module
#
module kraken:
    snakefile:
        "rules/kraken.smk"
    config:
        config
    skip_validation:
        True


use rule * from kraken as kraken_*


#
# Assembly Module
#
module assembly:
    snakefile:
        "rules/assembly.smk"
    config:
        config
    skip_validation:
        True


use rule * from assembly as assembly_*


#
# Utils Module
#
module utils:
    snakefile:
        "rules/utils.smk"
    config:
        config


#
# RGI Module
#
module rgi:
    snakefile:
        "rules/RGI.smk"
    config:
        config


use rule * from rgi as rgi_*


#
# Binning Module
#
module binning:
    snakefile:
        "rules/binning.smk"
    config:
        config


use rule * from binning as binning_*


#
# annotation Module
#
module annotate:
    snakefile:
        "rules/annotate.smk"
    config:
        config


use rule * from annotate as annotate_*


"""
Notes:
put all the logic here to connect pipeline stages (eg setting biobakery to using preprocessed results rather than config's R1 and R2
because the concat rule exists in both the preprocessing and kraken
snakefiles, we override the ins and outs of one of them.  Since the new
outputs aren't in rule all, this clips the rule from the dag

 The wildcard_constraints below ensures that the sample wildcard never ends with _shard001
 needing this probably means I could specify file names more cleanly :/
"""
if config["stage"] == "all":

    use rule cat_pair from biobakery as biobakery_cat_pair with:
        input:
            R1="hostdepleted/{sample}_1.fastq.gz",
            R2="hostdepleted/{sample}_2.fastq.gz",

    use rule RGI from rgi as rgi_RGI with:
        input:
            R1="hostdepleted/{sample}_1.fastq.gz",
            R2="hostdepleted/{sample}_2.fastq.gz",
            db=config["CARD_db_json"],

    use rule SPAdes_run from assembly as assembly_SPAdes_run with:
        input:
            R1="hostdepleted/{sample}_1.fastq.gz",
            R2="hostdepleted/{sample}_2.fastq.gz",

    use rule concat_R1_R2 from kraken as kraken_concat_R1_R2 with:
        input:
            R1=touch("input_F"),
            R2=touch("input_R"),
        output:
            R1=temp(touch("output_F")),
            R2=temp(touch("output_R")),

    use rule kraken_standard_run from kraken as kraken_kraken_standard_run with:
        input:
            R1="trimmed/{sample}_shard{shard}_trim_R1.fastq.gz",
            R2="trimmed/{sample}_shard{shard}_trim_R2.fastq.gz",
            db=config["kraken2_db"],
        output:
            out="kraken2/{sample}_shard{shard}_kraken2.out",
            unclass_R1="kraken2/{sample}_shard{shard}_kraken2_unclassified_1.fastq",
            unclass_R2="kraken2/{sample}_shard{shard}_kraken2_unclassified_2.fastq",
            report=temp("kraken2/{sample}_shard{shard}_kraken2.report"),
        log:
            e="logs/kraken_{sample}_shard{shard}.e",

    use rule compress_kraken_unclassified from kraken as kraken_compress_kraken_unclassified with:
        input:
            R1=[
                f"kraken2/{{sample}}_shard{shard}_kraken2_unclassified_1.fastq"
                for shard in SHARDS
            ],
            R2=[
                f"kraken2/{{sample}}_shard{shard}_kraken2_unclassified_2.fastq"
                for shard in SHARDS
            ],

    use rule kraken_merge_shards from kraken as kraken_kraken_merge_shards with:
        input:
            #reports = rules.kraken_kraken_standard_run.output.report,
            reports=[
                f"kraken2/{{sample}}_shard{shard}_kraken2.report" for shard in SHARDS
            ],
        output:
            out="kraken2/{sample}_kraken2.report",
        wildcard_constraints:
            sample=".+(?<!shard\d\d\d)",

else:
    pass


# the above else: pass is needed to make snakefmt happy


outputs = {
    "all": [
        rules.preprocess_all.input,
        rules.biobakery_all.input,
        rules.assembly_all.input,
        rules.kraken_all.input,
        rules.rgi_all.input,
        rules.binning_all.input,
        rules.annotate_all.input,
    ],
    "preprocess": [
        rules.preprocess_all.input,
    ],
    "biobakery": [
        rules.biobakery_all.input,
    ],
    "assembly": [
        rules.assembly_all.input,
    ],
    "kraken": [
        rules.kraken_all.input,
    ],
    "rgi": [
        rules.rgi_all.input,
    ],
    "binning": [
        rules.binning_all.input,
    ],
    "annotate": [
        rules.annotate_all.input,
    ],
}


rule all:
    input:
        outputs[config["stage"]],
    default_target: True
